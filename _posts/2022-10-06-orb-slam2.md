---
layout: post
title: "ORB SLAM2 build"
author: "jungjik.lee"
categories: article
tags: [slam, orb]
---

# VR에서의 SLAM
 - Head Tracking을 하기 위해서는 VO, SLAM이 필요하다.
 - GearVR이나 Daydream 같은 경우엔 자이로센서와 가속도 센서로 3DoF만 구현했기 때문에 SLAM이 필요 없는데,
 - Oculus나 Vive 같은 경우엔 6DoF를 필요로 하기 때문에 SLAM을 필요로 한다.

# ORB_SLAM
 - ORB SLAM 은 Feature Detecting을 [ORB](https://docs.opencv.org/3.4/d1/d89/tutorial_py_orb.html)를 통해서 찾고 
 Feature Matching을 해서 Trajectory를 찾는다.
 - ![Architecture](https://fnwinter.github.io/assets/img/slam/ORB-SLAM-system-overview-showing-all-the-steps-performed-by-the-tracking-local-mapping.png)

# ORB SLAM repo
 - [github link](https://github.com/raulmur/ORB_SLAM2)

# Build
 - dependency
   - [opencv install](https://docs.opencv.org/4.x/d7/d9f/tutorial_linux_install.html)
    - 여기서 opencv는 3.4 버전으로 설치했다.
   - Pangolin [link](https://github.com/stevenlovegrove/Pangolin)
   - libeigen3-dev, libgtk2.0-dev 를 설치해 준다.
 - build
    - C++11대신에 C++14를 사용하기 위해서 아래의 명령 실행
        - sed -i 's/++11/++14/g' CMakeLists.txt
    - CMakeList.txt 에서 아래와 같이 수정
        - find_package(Eigen3 3.3.7 REQUIRED NO_MODULE)
    - 코드 버그 수정
        - include/LoopClosing.h
        <pre><code>
        -Eigen::aligned_allocator<std::pair<const KeyFrame*, g2o::Sim3> > > KeyFrameAndPose;
        +Eigen::aligned_allocator<std::pair<KeyFrame* const, g2o::Sim3> > > KeyFrameAndPose;
        </code></pre>
        - include/System.h 에 아래의 include 추가
        <pre><code>
        +#include <unistd.h>
        +#include <stdio.h>
        +#include <stdlib.h>
        </code></pre>
    - 빌드 실행
        <pre><code>
        cd ORB_SLAM2
        chmod +x build.sh
        ./build.sh
        </code></pre>

# Run
 - https://vision.in.tum.de/data/datasets/rgbd-dataset/download
   여기서 dataset을 다운로드 받고
 - ./Examples/Monocular/mono_tum Vocabulary/ORBvoc.txt Examples/Monocular/TUMX.yaml PATH_TO_SEQUENCE_FOLDER
   이런식을 실행하면 동작함.

# Profile
 - Raspberry Pi 4에서 Mono로 돌렸을 때 몇 frame이 나오는지 궁금하다.
 - ORB SLAM의 경우엔 연산량이 많아서 무겁다고 해서 VO정도의 기능이 있는 SVO와 비교해 보고 싶다.